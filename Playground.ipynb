{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import PIL\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import copy\n",
    "#\n",
    "import config.config_flags as Config\n",
    "import data_load.data_provider as dp\n",
    "import runner as runner\n",
    "import utils.task_helper as th\n",
    "import utils.helper as helper\n",
    "import datasetconf as DC\n",
    "import TaskClass as TaskClass\n",
    "import Task as Task\n",
    "import TestNets as TestNets\n",
    "import maml as MAML\n",
    "#\n",
    "_ = importlib.reload(Config)\n",
    "_ = importlib.reload(th)\n",
    "_ = importlib.reload(dp)\n",
    "_ = importlib.reload(runner)\n",
    "_ = importlib.reload(helper)\n",
    "_ = importlib.reload(DC)\n",
    "_ = importlib.reload(TaskClass)\n",
    "_ = importlib.reload(Task)\n",
    "_ = importlib.reload(TestNets)\n",
    "_ = importlib.reload(MAML)"
   ]
  },
  {
   "source": [
    "## Loading tasks from local img folders."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1 = Task.create_task_given(\n",
    "    task_friendly_name='Task1',\n",
    "    dataset_name='boat',\n",
    "    class_names=['Gondola', 'Motopontonerettangolare'], #n-way\n",
    "    len_support_dataset=3, #k-shot\n",
    "    len_query_dataset=2,   #k-shot\n",
    "    let_test_dataset=5, # Number of test cases per class\n",
    "    transformer=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(224),\n",
    "        torchvision.transforms.CenterCrop(224),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225])]),\n",
    "    img_size=224,\n",
    "    start_class_id=0)\n",
    "task1.reset_train_session()\n",
    "#\n",
    "task2 = Task.create_task_given(\n",
    "    task_friendly_name='Task2',\n",
    "    dataset_name='boat',\n",
    "    class_names=['Raccoltarifiuti', 'Water'],\n",
    "    len_support_dataset=3,\n",
    "    len_query_dataset=2,\n",
    "    let_test_dataset=5, # Number of test cases per class\n",
    "    transformer=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(224),\n",
    "        torchvision.transforms.CenterCrop(224),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225])]),\n",
    "    img_size=224,\n",
    "    start_class_id=2)\n",
    "task2.reset_train_session()\n",
    "#\n",
    "TASKS = [task1, task2]\n",
    "LEN_CLASSES = sum(len(task.task_classes) for task in TASKS)\n",
    "CLASSES_NAMES = [taskclass.class_friendly_name for task in TASKS for taskclass in task.task_classes]\n",
    "NUM_IN_CHANNELS = 3 # RGB"
   ]
  },
  {
   "source": [
    "## Create Tak Objects"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set tensor device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Generate Task DB or load from filesystem\n",
    "print(\"Generating tasks and compute their alpha weights\")\n",
    "runner.populate_db()\n",
    "\n",
    "#Perform top-m filtering\n",
    "print(\"Filtering top-m alpha weights and training tasks\")\n",
    "alpha_weights, train_db = runner.top_m_filtering()\n",
    "\n",
    "#Get target task from filesystem\n",
    "test_path = helper.get_task_dataset_path(\"test\")\n",
    "test_db = runner.unpickle(test_path)\n",
    "\n",
    "#Get train data embeddings\n",
    "print(\"Fetching train embeddings\")\n",
    "train_provider = dp.DataProvider(\"train\", debug=False, verbose=False)\n",
    "train_tr_size = Config.TRAINING_NUM_OF_EXAMPLES_PER_CLASS\n",
    "train_val_size = Config.VALIDATION_NUM_OF_EXAMPLES_PER_CLASS\n",
    "print(\"Generating training tasks\")\n",
    "train_tasks = th.generate_tasks(train_db, train_provider, train_tr_size, train_val_size, device)\n",
    "\n",
    "#Get train data embeddings\n",
    "print(\"Fetching test embeddings\")\n",
    "test_provider = dp.DataProvider(\"test\", debug=False, verbose=False)\n",
    "test_tr_size = 0\n",
    "test_val_size = Config.TEST_VALIDATION_NUM_OF_EXAMPLES_PER_CLASS\n",
    "print(\"Generating test tasks\")\n",
    "test_tasks = th.generate_tasks(test_db, test_provider, test_tr_size, test_val_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(100, 1)\n100\n[0.23874423]\n0.2387442287581507\n"
     ]
    }
   ],
   "source": [
    "print(alpha_weights.shape)\n",
    "print(len(train_tasks))\n",
    "print(alpha_weights[1])\n",
    "print(alpha_weights[1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_net = TestNets.TestNet224x224(n_channels_in=NUM_IN_CHANNELS, n_classes=LEN_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAML.maml_nn_classifier_learn(\n",
    "    test_net=test_net,\n",
    "    tasks=TASKS,\n",
    "    # inner_epochs: int = 1, # Not implemented yet.\n",
    "    meta_epochs=20,\n",
    "    # inner_lr: float = 0.001,\n",
    "    # outer_lr: float = 0.001,\n",
    "    # loss_function = torch.nn.CrossEntropyLoss()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat until convergence:\n",
    "TASML.tasml_epoch_nn_classifier_learn(\n",
    "    test_net=test_net,\n",
    "    tasks=train_tasks,\n",
    "    alpha_weights=alpha_weights,\n",
    "    # inner_epochs: int = 1, # Feature not implemented.\n",
    "    # inner_lr: float = 0.001,\n",
    "    # outer_lr: float = 0.001,\n",
    "    # loss_function = torch.nn.CrossEntropyLoss()\n",
    "):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}